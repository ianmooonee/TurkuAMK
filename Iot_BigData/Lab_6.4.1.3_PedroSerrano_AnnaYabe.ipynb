{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Title](Images/cisco.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab - Image Processing Change Detection\n",
    "\n",
    "### Objectives\n",
    "<p>\n",
    "<li>**Part 1: Learn About Computer Imaging**</li>\n",
    "<li>**Part 2: Capture Images**</li>\n",
    "<li>**Part 3: Change Detection**</li>\n",
    "<li>**Part 4: Explanation and Application**</li>\n",
    "\n",
    "### Scenario/Background\n",
    "Detecting moving objects in a scene is one of the most important tasks in computer vision. It is useful for video surveillance, for instance, but it is usually the basis for other, more complex tasks.\n",
    "\n",
    "Usually the way this task is performed is by building a model of an empty scene and comparing each newly captured frame to it. When the model of the empty scene is different from the current scene, it means that something in the image has changed. \n",
    "\n",
    "In this lab, we are going to use a video camera attached to the Raspberry Pi to capture videos and images. We will build a very simple background model that will allow us to detect changes in the scene that the camera is capturing. We are capturing the images and converting them into matrices of numbers that can be operated on mathematically. This is different from capturing images and saving them as files.\n",
    "### Required Resources\n",
    "<p>\n",
    "* 1 PC with Internet access\n",
    "* Raspberry Pi version 2 or higher\n",
    "* Python libraries: numpy, cv2, picamera, time, pyplot, numpy\n",
    "* Picamera V2 module\n",
    "\n",
    "The Raspberry Pi camera module was connected and installed in a previous lab. This lab assumes that the installation and testing of the camera module have previously been completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your name here:\n",
    "# Your student ID here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Learn About Computer Imaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the kind of data we are going to work with: digital images and videos.\n",
    "\n",
    "A digital image is a matrix composed of pixels. Each pixel corresponds to a position inside of the image and contains information regarding the color of the image at that location. If the image is grayscale, each pixel contains a number that identifies the `level of gray` in that position. If we are looking at a color image, then each pixel contains a vector that encodes a color according to a certain color map. For instance, if we are using the RGB color map, each color is encoded by a group of three numbers. The numbers reprent the quantity of red, blue and green that makes up the color of the pixel. \n",
    "\n",
    "So, if we want to compare what we see versus what the computer sees, it would be something like this:\n",
    "\n",
    "![title](Images/lisa_n.png)\n",
    "\n",
    "Each pixel in an image that is using the RGB color space has three RGB values that range from 0 to 255 that define the color of that pixel. An image that is 256 pixels high and 256 pixles wide has 65,536 pixels. Each pixel has 24 bits of color information associated with it in an RGB color space. (The 24 bits consist of eight bits each for the red, green, and blue color channels.) The figure shows a numeric array that represents a 16x16 pixel area of the larger image. The values in the numeric array for each pixel represent the red value in that pixel. The pixels also have green and blue values that are not shown for clarity. The combination of the red, green, and blue values can depict 16,777,216 color variations (256 to the third power).\n",
    "\n",
    "Computer vision is a demanding computer task, and it requires a lot of work in terms of pre-processing to transform a raw digital image into a form that is understandable by a computer as data.\n",
    "\n",
    "The resolution of an image (or a video) is the number of pixels contained in the image (or each frame), and it is usually expressed by the number of rows and the number of colums (e.g, 256x256 means that an image has 256 rows and 256 columns of pixels).\n",
    "\n",
    "A digital video is a sequence of frames, and each frame is a digital image. Digital videos can have different frame rates that are expressed as the number of images per second. Video standards vary, but a full-motion digital video is usually around 30 frames per second. Other frame rates can be used depending on the purpose of the video and the amount of bandwidth and storage that are available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Capture Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the lab, we will use Python to automatically capture a series of images.\n",
    "\n",
    "##### Step 1: Setup the environment.\n",
    "Import all the libraries we need to perform the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a scikit-image\n",
    "#!pip install scikit-image\n",
    "\n",
    "# Or update if you allready have it\n",
    "\n",
    "#!pip install --upgrade scikit-image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code cell 1\n",
    "# import the necessary packages\n",
    "import cv2\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### b) Capture a sequence of images.\n",
    "In order to capture image sequences, we will create an infinite loop and capture images periodically as the loop repeats. Add or move items whithin the frame. You will see the video update after a short delay. This is like a very low frame rate video. \n",
    "\n",
    "In order to go on to code cell 4, stop code cell 3 by clicking the button with the square icon to the left of the code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def videoCapture (frame_rate):\n",
    "    #Capture the video flux with openCV (We can change 0 to 1,2,... if multiple cameras)\n",
    "    \n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    \n",
    "    image_counter = 0\n",
    "    prev_time = 0\n",
    "\n",
    "    #Main loop, runinng unless of CTRL+C or keyboard input\n",
    "    while True:\n",
    "        try:\n",
    "            #Read the next frame into buffer\n",
    "            ret,buffer_frame = video_capture.read() # First frame\n",
    "            \n",
    "            #Set framerate\n",
    "            time_elapsed = time.time() - prev_time\n",
    "            \n",
    "            if time_elapsed > 1./frame_rate:\n",
    "                prev_time = time.time()\n",
    "\n",
    "                #Display captured frame, so we can see what is happening\n",
    "                cv2.imshow('img', buffer_frame)\n",
    "                cv2.waitKey(1) # Image not displayed if line removed\n",
    "                \n",
    "\n",
    "        #Avoid error when stopping program\n",
    "        except KeyboardInterrupt:\n",
    "            print('Done')\n",
    "            break\n",
    "\n",
    "    #Stop video feed and close window\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Be patient, takes some time to launch in JNotebook.\n",
    "#Press Jupyter Notebook STOP button to stop cell.\n",
    "\n",
    "fps=25 # frame rate = frames per second\n",
    "videoCapture(fps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Change Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Detect moving objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to detect a change in the captured image, the stored background image will be subtracted from the current frame. Because of noise, the difference between the stored background and the current background will not always be exactly zero if no change has occurred. In order to avoid falsely detecting change, we will have to set a threshold that will let us decide whether the difference between the two images is small enough to be considered zero or if we think that something is actually moving in the scene.\n",
    "\n",
    "Execute the following code. The code will loop indefinately until it is stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event1 : Something moving\n",
      "Event2 : Something moving\n",
      "Event3 : Something moving\n",
      "Event4 : Something moving\n",
      "Event5 : Something moving\n",
      "Event6 : Something moving\n",
      "Event7 : Something moving\n",
      "Event8 : Something moving\n",
      "Event9 : Something moving\n",
      "Event10 : Something moving\n",
      "Event11 : Something moving\n",
      "Event12 : Something moving\n",
      "Event13 : Something moving\n",
      "Event14 : Something moving\n",
      "Event15 : Something moving\n",
      "Event16 : Something moving\n",
      "Event17 : Something moving\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "#scikit-image, for comparison, SSIM algorithm\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# --- VARS ---\n",
    "# Threshold, if the error is under it, we trigger an alert\n",
    "# 1 is perfect match between 2 images\n",
    "# Found that we had to lower it to deal with noise and micro movements\n",
    "similarityValue = 0.90\n",
    "\n",
    "#Capture the video flux with openCV (We can change 0 to 1,2,... if multiple cameras)'\n",
    "\n",
    "video_capture =  cv2.VideoCapture(0)\n",
    "\n",
    "# First, we need to initialise the stored frame\n",
    "# right now it's empty so we have nothing to compare to\n",
    "\n",
    "# Get the actual frame\n",
    "ret,buffer_frame = video_capture.read()\n",
    "\n",
    "#Transform picture to GrayScale, easier to compare\n",
    "buffer_frame = cv2.cvtColor(buffer_frame, cv2.COLOR_BGR2GRAY)\n",
    "      \n",
    "#Store actual frame, so now we can start comparing\n",
    "previous_frame = buffer_frame\n",
    "\n",
    "#We do not need to compare all the frames\n",
    "#let's compare every 10 frames (Approx every ~0.4s for a 24fps camera)\n",
    "comparison_frequency = 10\n",
    "\n",
    "#Counter for video frames, we already got 1 image, so init at 1\n",
    "image_counter = 1\n",
    "\n",
    "#Counter for printing events with number\n",
    "event_counter = 0\n",
    "\n",
    "#Main loop, runinng unless of CTRL+C or keyboard input\n",
    "while True:\n",
    "    try:\n",
    "        #Read the next frame into buffer\n",
    "        ret,buffer_frame = video_capture.read()\n",
    "    \n",
    "        #If we don't have images anymore, exit\n",
    "        if buffer_frame is None:\n",
    "            break\n",
    "        \n",
    "        #Switch to gray\n",
    "        buffer_frame = cv2.cvtColor(buffer_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        #Compare every 10 frames\n",
    "        if image_counter == comparison_frequency:\n",
    "            #Get error value\n",
    "            ssim_index = ssim(previous_frame, buffer_frame)\n",
    "        \n",
    "            #If error under threshold, trigger warning\n",
    "            if ssim_index < similarityValue:\n",
    "                event_counter +=1\n",
    "                print('Event'+str(event_counter)+' : Something moving')   \n",
    "                \n",
    "              \n",
    "            \n",
    "            #Store current frame as new reference for comparison\n",
    "            previous_frame = buffer_frame\n",
    "           \n",
    "            #Display captured frame, so we can see what is happening\n",
    "            cv2.imshow('img', buffer_frame)\n",
    "            cv2.waitKey(1) # Image not displayed if line removed\n",
    "            \n",
    "            #if comparison happened, reset frame counter\n",
    "            image_counter=0\n",
    "            \n",
    "        #Increment at each loop / captured frame\n",
    "        image_counter+=1\n",
    "    \n",
    "    #Avoid error when stopping program\n",
    "    except KeyboardInterrupt:\n",
    "        print('All done')\n",
    "        break\n",
    "        \n",
    "#Stop video feed and close window\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4:  Application\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application\n",
    "Digital video cameras have become inexpensive, plentiful, and practical to use. Video cameras that are connected to networks can be seen in many cities and businesses. Some of these cameras are connected to the Internet. The streams of video data that they produce are processed and analyzed at the network edge or in the Cloud. What is this video data used for?\n",
    "\n",
    "An obvious application is for security and surveillance. Basic change detection algorithms like the one demonstrated in this lab could be used to detect the actions of people or the movement of things. Change detection can be used to detect when parking places become vacant or when store shelves are empty. In traffic management, a change detection process can be used to compare the current conditions on a highway to the expected conditions for that time and day. A differrence may indicate a traffic jam in or near the area that the camera is monitoring. This could be used to alert public safety personnel of the need to investigate road conditions.\n",
    "\n",
    "Can you think of any other applications for analysis of video data and change detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Security Camera  \n",
    "> Connected doorbell  \n",
    "> Animals detection / counter  \n",
    "> Poacher detect  \n",
    "> Autonomous cars  \n",
    "> Pattern detections  \n",
    "> ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='0.5'>&copy; 2017 Cisco and/or its affiliates. All rights reserved. This document is Cisco Public.<font>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
